"""
Tests for the AI Assistant app.
Tests AI functionality, Gemini API integration, and AI-powered features.
"""

import json
from unittest.mock import Mock, patch, MagicMock
from django.test import TestCase, Client
from django.urls import reverse
from django.contrib.auth.models import User
from django.core.exceptions import ValidationError
from django.utils import timezone
import pytest

from tests.factories import UserFactory
from tests.utils import BaseTestCase
from ai.models import *  # Import AI models
from ai import views
from ai import utils


# ===== AI MODEL TESTS =====


@pytest.mark.models
class AIModelTest(BaseTestCase):
    """Test AI-related models."""

    def test_ai_conversation_model(self):
        """Test AI conversation model if it exists."""
        # This will test any AI conversation tracking models
        try:
            from ai.models import AIConversation, AIMessage

            user = UserFactory()
            conversation = AIConversation.objects.create(
                user=user, title="Test AI Chat", created_at=timezone.now()
            )

            self.assertEqual(conversation.user, user)
            self.assertEqual(conversation.title, "Test AI Chat")
            self.assertTrue(conversation.created_at)

            # Test string representation
            self.assertIn("Test AI Chat", str(conversation))

        except ImportError:
            # Skip if AI conversation models don't exist
            pass

    def test_ai_message_model(self):
        """Test AI message model if it exists."""
        try:
            from ai.models import AIConversation, AIMessage

            user = UserFactory()
            conversation = AIConversation.objects.create(user=user, title="Test Chat")

            message = AIMessage.objects.create(
                conversation=conversation,
                role="user",
                content="Hello AI",
                timestamp=timezone.now(),
            )

            self.assertEqual(message.conversation, conversation)
            self.assertEqual(message.role, "user")
            self.assertEqual(message.content, "Hello AI")

            # Test message ordering
            self.assertTrue(message.timestamp)

        except ImportError:
            # Skip if AI message models don't exist
            pass

    def test_ai_settings_model(self):
        """Test AI settings/configuration model if it exists."""
        try:
            from ai.models import AISettings

            settings = AISettings.objects.create(
                api_key_encrypted="encrypted_key",
                model_name="gemini-pro",
                max_tokens=1000,
                temperature=0.7,
            )

            self.assertEqual(settings.model_name, "gemini-pro")
            self.assertEqual(settings.max_tokens, 1000)
            self.assertEqual(settings.temperature, 0.7)

        except ImportError:
            # Skip if AI settings model doesn't exist
            pass


# ===== GEMINI API INTEGRATION TESTS =====


@pytest.mark.api
class GeminiAPITest(BaseTestCase):
    """Test Gemini API integration."""

    @patch("ai.utils.genai")  # Adjust import path as needed
    def test_generate_ai_response_success(self, mock_genai):
        """Test successful AI response generation."""
        # Mock Gemini API response
        mock_model = Mock()
        mock_response = Mock()
        mock_response.text = "This is an AI generated response."
        mock_model.generate_content.return_value = mock_response
        mock_genai.GenerativeModel.return_value = mock_model

        # Test AI response generation
        try:
            from ai.utils import generate_ai_response  # Adjust import

            response = generate_ai_response("What is Django?")

            self.assertEqual(response, "This is an AI generated response.")
            mock_model.generate_content.assert_called_once_with("What is Django?")

        except ImportError:
            # Skip if generate_ai_response function doesn't exist
            pass

    @patch("ai.utils.genai")
    def test_generate_ai_response_failure(self, mock_genai):
        """Test AI response generation failure handling."""
        # Mock API failure
        mock_genai.GenerativeModel.side_effect = Exception("API Error")

        try:
            from ai.utils import generate_ai_response

            # Should handle API errors gracefully
            with self.assertRaises(Exception):
                generate_ai_response("Test prompt")

        except ImportError:
            # Skip if function doesn't exist
            pass

    @patch("ai.utils.genai")
    def test_ai_response_with_context(self, mock_genai):
        """Test AI response generation with conversation context."""
        mock_model = Mock()
        mock_response = Mock()
        mock_response.text = "Response with context."
        mock_model.generate_content.return_value = mock_response
        mock_genai.GenerativeModel.return_value = mock_model

        try:
            from ai.utils import generate_ai_response_with_context

            conversation_history = [
                {"role": "user", "content": "Hello"},
                {"role": "assistant", "content": "Hi there!"},
            ]

            response = generate_ai_response_with_context(
                "How are you?", conversation_history
            )

            self.assertEqual(response, "Response with context.")

        except ImportError:
            # Skip if function doesn't exist
            pass

    def test_api_key_configuration(self):
        """Test API key configuration and validation."""
        try:
            from ai.utils import configure_genai_api
            from django.conf import settings

            # Test API key configuration
            api_key = getattr(settings, "GEMINI_API_KEY", None)

            if api_key:
                # Test that API is configured
                configure_genai_api()
                # If no exception, configuration is successful
                self.assertTrue(True)
            else:
                # Test handling of missing API key
                with self.assertRaises((ValueError, AttributeError)):
                    configure_genai_api()

        except ImportError:
            # Skip if configuration function doesn't exist
            pass


# ===== AI VIEW TESTS =====


@pytest.mark.views
class AIViewTest(BaseTestCase):
    """Test AI-related views."""

    def test_ai_chat_view_get(self):
        """Test AI chat view GET request."""
        try:
            response = self.client.get(reverse("ai:chat"))
            self.assertEqual(response.status_code, 200)
            self.assertContains(response, "chat")  # Adjust based on template

        except:
            # Skip if AI chat view doesn't exist
            pass

    def test_ai_chat_view_requires_authentication(self):
        """Test that AI chat requires authentication."""
        try:
            # Test unauthenticated access
            response = self.client.get(reverse("ai:chat"))

            if response.status_code == 302:
                # Should redirect to login
                self.assertTrue("login" in response.url)

            # Test authenticated access
            user = UserFactory()
            self.client.force_login(user)

            response = self.client.get(reverse("ai:chat"))
            self.assertEqual(response.status_code, 200)

        except:
            # Skip if view doesn't exist
            pass

    @patch("ai.views.generate_ai_response")
    def test_ai_chat_post_request(self, mock_generate):
        """Test AI chat POST request."""
        mock_generate.return_value = "AI response to your question."

        user = UserFactory()
        self.client.force_login(user)

        chat_data = {
            "message": "What is artificial intelligence?",
            "conversation_id": None,
        }

        try:
            response = self.client.post(
                reverse("ai:chat"),
                data=json.dumps(chat_data),
                content_type="application/json",
            )

            if response.status_code == 200:
                response_data = json.loads(response.content)
                self.assertIn("response", response_data)
                self.assertEqual(
                    response_data["response"], "AI response to your question."
                )

                # Verify AI function was called
                mock_generate.assert_called_once_with(
                    "What is artificial intelligence?"
                )

        except:
            # Skip if AI chat endpoint doesn't exist
            pass

    def test_ai_conversation_history_view(self):
        """Test AI conversation history view."""
        user = UserFactory()
        self.client.force_login(user)

        try:
            response = self.client.get(reverse("ai:conversations"))
            self.assertEqual(response.status_code, 200)

            # Should show user's conversations
            self.assertContains(response, "conversation")  # Adjust based on template

        except:
            # Skip if conversations view doesn't exist
            pass

    def test_ai_settings_view(self):
        """Test AI settings configuration view."""
        # Test with staff/admin user
        admin_user = UserFactory(is_staff=True, is_superuser=True)
        self.client.force_login(admin_user)

        try:
            response = self.client.get(reverse("ai:settings"))
            self.assertEqual(response.status_code, 200)

            # Should show AI configuration options
            self.assertContains(response, "settings")

        except:
            # Skip if settings view doesn't exist
            pass


# ===== AI UTILITY TESTS =====


@pytest.mark.unit
class AIUtilityTest(BaseTestCase):
    """Test AI utility functions."""

    def test_sanitize_ai_input(self):
        """Test AI input sanitization."""
        try:
            from ai.utils import sanitize_ai_input

            # Test normal input
            clean_input = sanitize_ai_input("What is Django framework?")
            self.assertEqual(clean_input, "What is Django framework?")

            # Test input with potential injection
            malicious_input = "<script>alert('xss')</script>What is Django?"
            sanitized = sanitize_ai_input(malicious_input)
            self.assertNotIn("<script>", sanitized)

            # Test very long input
            long_input = "A" * 10000
            sanitized_long = sanitize_ai_input(long_input)
            self.assertTrue(len(sanitized_long) <= 5000)  # Adjust max length

        except ImportError:
            # Skip if utility function doesn't exist
            pass

    def test_format_ai_response(self):
        """Test AI response formatting."""
        try:
            from ai.utils import format_ai_response

            # Test markdown formatting
            raw_response = "**Bold text** and *italic text*"
            formatted = format_ai_response(raw_response)

            # Should convert markdown to HTML or keep markdown format
            self.assertIsInstance(formatted, str)
            self.assertTrue(len(formatted) > 0)

        except ImportError:
            # Skip if utility function doesn't exist
            pass

    def test_conversation_context_builder(self):
        """Test conversation context building."""
        try:
            from ai.utils import build_conversation_context

            messages = [
                {"role": "user", "content": "Hello"},
                {"role": "assistant", "content": "Hi there!"},
                {"role": "user", "content": "How are you?"},
            ]

            context = build_conversation_context(messages)

            self.assertIsInstance(context, (str, list))
            # Should include all messages in some format

        except ImportError:
            # Skip if utility function doesn't exist
            pass

    def test_ai_response_caching(self):
        """Test AI response caching mechanism."""
        try:
            from ai.utils import get_cached_response, cache_ai_response

            query = "What is Python programming?"
            response = "Python is a programming language."

            # Test caching
            cache_ai_response(query, response)

            # Test retrieval
            cached = get_cached_response(query)
            self.assertEqual(cached, response)

        except ImportError:
            # Skip if caching functions don't exist
            pass


# ===== AI SECURITY TESTS =====


@pytest.mark.security
class AISecurityTest(BaseTestCase):
    """Test AI functionality security measures."""

    def test_rate_limiting_ai_requests(self):
        """Test rate limiting on AI requests."""
        user = UserFactory()
        self.client.force_login(user)

        # Make multiple rapid requests
        for i in range(20):  # Adjust based on rate limit
            try:
                response = self.client.post(
                    reverse("ai:chat"),
                    data=json.dumps({"message": f"Test message {i}"}),
                    content_type="application/json",
                )

                if response.status_code == 429:  # Too Many Requests
                    # Rate limiting is working
                    break

            except:
                # Skip if AI endpoint doesn't exist
                break

    def test_input_validation_and_sanitization(self):
        """Test input validation for AI requests."""
        user = UserFactory()
        self.client.force_login(user)

        malicious_inputs = [
            "<script>alert('xss')</script>",
            "'; DROP TABLE users; --",
            "{{7*7}}",  # Template injection
            "{{config}}",  # Configuration exposure
        ]

        for malicious_input in malicious_inputs:
            try:
                response = self.client.post(
                    reverse("ai:chat"),
                    data=json.dumps({"message": malicious_input}),
                    content_type="application/json",
                )

                # Should either reject input or sanitize it
                if response.status_code == 200:
                    response_data = json.loads(response.content)
                    # Response should not contain unescaped malicious content
                    self.assertNotIn("<script>", response_data.get("response", ""))

            except:
                # Skip if AI endpoint doesn't exist
                break

    def test_ai_response_content_filtering(self):
        """Test filtering of inappropriate AI responses."""
        try:
            from ai.utils import filter_ai_response

            # Test inappropriate content filtering
            inappropriate_responses = [
                "This contains sensitive personal information...",
                "Here's how to hack into systems...",
            ]

            for response in inappropriate_responses:
                filtered = filter_ai_response(response)

                # Should be filtered or flagged
                self.assertNotEqual(filtered, response)

        except ImportError:
            # Skip if content filtering doesn't exist
            pass

    def test_api_key_security(self):
        """Test API key security measures."""
        from django.conf import settings

        # API key should not be exposed in client-side code
        try:
            response = self.client.get(reverse("ai:chat"))

            if response.status_code == 200:
                # Check that API key is not in response
                api_key = getattr(settings, "GEMINI_API_KEY", "")
                if api_key:
                    self.assertNotIn(api_key, str(response.content))

        except:
            # Skip if AI chat view doesn't exist
            pass


# ===== AI INTEGRATION TESTS =====


@pytest.mark.integration
class AIIntegrationTest(BaseTestCase):
    """Test AI integration with other app components."""

    def test_ai_with_user_profiles(self):
        """Test AI integration with user profiles."""
        user = UserFactory(first_name="John", last_name="Doe")
        self.client.force_login(user)

        try:
            # Test that AI can access user context
            response = self.client.post(
                reverse("ai:chat"),
                data=json.dumps({"message": "What is my name?", "use_profile": True}),
                content_type="application/json",
            )

            if response.status_code == 200:
                response_data = json.loads(response.content)
                # AI should be able to reference user's name
                self.assertIn("John", response_data.get("response", ""))

        except:
            # Skip if feature doesn't exist
            pass

    def test_ai_conversation_persistence(self):
        """Test AI conversation persistence across sessions."""
        user = UserFactory()
        self.client.force_login(user)

        try:
            # Start a conversation
            response1 = self.client.post(
                reverse("ai:chat"),
                data=json.dumps({"message": "Remember my name is Alice"}),
                content_type="application/json",
            )

            if response1.status_code == 200:
                conversation_id = json.loads(response1.content).get("conversation_id")

                if conversation_id:
                    # Continue conversation
                    response2 = self.client.post(
                        reverse("ai:chat"),
                        data=json.dumps(
                            {
                                "message": "What is my name?",
                                "conversation_id": conversation_id,
                            }
                        ),
                        content_type="application/json",
                    )

                    if response2.status_code == 200:
                        response_data = json.loads(response2.content)
                        # AI should remember the name from previous message
                        self.assertIn("Alice", response_data.get("response", ""))

        except:
            # Skip if conversation persistence doesn't exist
            pass

    @patch("ai.utils.genai")
    def test_ai_error_handling_and_fallbacks(self, mock_genai):
        """Test AI error handling and fallback mechanisms."""
        # Mock API failure
        mock_genai.GenerativeModel.side_effect = Exception("API Unavailable")

        user = UserFactory()
        self.client.force_login(user)

        try:
            response = self.client.post(
                reverse("ai:chat"),
                data=json.dumps({"message": "Test message"}),
                content_type="application/json",
            )

            if response.status_code == 200:
                response_data = json.loads(response.content)

                # Should have error handling with fallback response
                self.assertIn("error", response_data or "response" in response_data)

                # Should provide user-friendly error message
                error_msg = response_data.get(
                    "error", response_data.get("response", "")
                )
                self.assertNotIn("Exception", error_msg)  # No raw exceptions

        except:
            # Skip if AI endpoint doesn't exist
            pass


# ===== AI PERFORMANCE TESTS =====


@pytest.mark.performance
class AIPerformanceTest(BaseTestCase):
    """Test AI functionality performance."""

    def test_ai_response_time(self):
        """Test AI response time performance."""
        user = UserFactory()
        self.client.force_login(user)

        import time

        try:
            start_time = time.time()

            response = self.client.post(
                reverse("ai:chat"),
                data=json.dumps({"message": "Quick test message"}),
                content_type="application/json",
            )

            end_time = time.time()
            response_time = end_time - start_time

            # Response should be reasonably fast (adjust threshold)
            self.assertLess(response_time, 10.0)  # 10 seconds max

            if response.status_code == 200:
                response_data = json.loads(response.content)
                self.assertIn("response", response_data)

        except:
            # Skip if AI endpoint doesn't exist
            pass

    def test_concurrent_ai_requests(self):
        """Test handling of concurrent AI requests."""
        import threading

        users = [UserFactory() for _ in range(3)]
        results = []

        def make_ai_request(user):
            client = Client()
            client.force_login(user)

            try:
                response = client.post(
                    reverse("ai:chat"),
                    data=json.dumps({"message": f"Test from {user.username}"}),
                    content_type="application/json",
                )
                results.append(response.status_code)
            except:
                results.append(404)  # Skip if endpoint doesn't exist

        # Create threads for concurrent requests
        threads = []
        for user in users:
            thread = threading.Thread(target=make_ai_request, args=(user,))
            threads.append(thread)
            thread.start()

        # Wait for all threads to complete
        for thread in threads:
            thread.join()

        # All requests should be handled successfully
        successful_requests = [r for r in results if r == 200]
        self.assertGreaterEqual(
            len(successful_requests), 1
        )  # At least one should succeed
